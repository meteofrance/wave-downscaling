seed_everything: true

model:
  class_path: ww3.plmodules.directplmodule.WW3DirectLightningModule
  init_args:
    residual_prediction: true
    lr_scheduler_interval: step
    model:
      class_path: mfai.pytorch.models.unetrpp.UNetRPP
      init_args:
        in_channels: 13  # 9 mfwam variables + 4 forcings
        out_channels: 9  # 9 ww3 variables
        input_shape:
          - 58
          - 94
        settings:
          autopad_enabled: True
    loss:
      class_path: ww3.plmodules.directplmodule.MSEPlusPerceptualLoss
      init_args:
        lambda_mse: 20
        lambda_perceptual: 1
        in_channels: 9
        resize_input: True
        pre_trained: True
        channel_iterative_mode: True
        feature_layer_ids: [4, 9, 16]
        feature_block_ids: [0, 1, 2]

data:
  batch_size: 16
  pct_in_train: 0.8
  num_workers: 10
  prefetch_factor: 4
  transforms_list:
    - class_path: ww3.transforms.NaNToNum
      init_args:
        downscaling_stride: 25
    - class_path: ww3.transforms.Normalize
  grids_list:
    - BRETAGNE0002
  wave_params:
    - cos_mdps
    - sin_mdps
    - cos_mdww
    - sin_mdww
    - mpps
    - mpww
    - shps
    - shww
    - swh
  include_arpege: true
  include_forcings: true
  downscaling_stride: 25  # We take one pixel every 25 pixels

trainer:
  max_steps: 75000
  logger:
    class_path: lightning.pytorch.loggers.TensorBoardLogger
    init_args:
      save_dir: /scratch/shared/ww3/logs/basic_expe/
      name: unetrpp_customloss
  callbacks:
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        filename: "{epoch:02d}-{val_loss:.2f}"
        monitor: val_loss
        mode: min
        save_top_k: 1    # Save the best model
        save_last: True  # Also save the last model
    - class_path: lightning.pytorch.callbacks.LearningRateMonitor
      init_args:
        logging_interval: step
