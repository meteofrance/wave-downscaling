seed_everything: true

model:
  class_path: ww3.plmodules.directplmodule.DirectLightningModule
  residual_prediction: true
  lr_scheduler_interval: step
  model:
    class_path: mfai.pytorch.models.unetrpp.UNetRPP
    init_args:
      in_channels: 13  # 9 mfwam variables + 4 forcings
      out_channels: 9  # 9 ww3 variables
      input_shape:
        - 58
        - 94
      settings:
        autopad_enabled: True
  loss:
    class_path: torch.nn.MSELoss

data:
  batch_size: 16
  pct_in_train: 0.8
  num_workers: 10
  prefetch_factor: 4
  transforms_list:
    - class_path: ww3.transforms.NaNToNum
      init_args:
        downscaling_stride: 25
    - class_path: ww3.transforms.Normalize
  grids_list:
    - BRETAGNE0002
  wave_params:
    - cos_mdps
    - sin_mdps
    - cos_mdww
    - sin_mdww
    - mpps
    - mpww
    - shps
    - shww
    - swh
  include_arpege: true
  include_forcings: true
  downscaling_stride: 25  # We take one pixel every 25 pixels

trainer:
  max_steps: 50000
  logger:
    class_path: lightning.pytorch.loggers.TensorBoardLogger
    init_args:
      save_dir: /scratch/shared/ww3/logs/basic_expe/
      name: unetrpp_mse
  callbacks:
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        filename: "{epoch:02d}-{val_loss:.2f}"
        monitor: val_loss
        mode: min
        save_top_k: 1    # Save the best model
        save_last: True  # Also save the last model
    - class_path: lightning.pytorch.callbacks.LearningRateMonitor
      init_args:
        logging_interval: step
